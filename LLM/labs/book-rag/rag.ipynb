{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the CSV File from the markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"Chapter1.md.csv\" has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Turn the text files into csv\n",
    "filepath = \"<FILEPATH HERE>\"\n",
    "filename = os.path.basename(filepath)\n",
    "\n",
    "markdown_content = \"\"\n",
    "\n",
    "# Simulating reading from a file\n",
    "with open(filepath, 'r', encoding='utf-8') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "# Splitting the content into paragraphs\n",
    "paragraphs = [p.strip() for p in markdown_content.split('\\n\\n') if p.strip()]\n",
    "\n",
    "# Specify the chapter number here\n",
    "chapter_number = filename #'001'\n",
    "\n",
    "# Path to the CSV file where the output will be saved\n",
    "csv_file_path = filename + '.csv'\n",
    "\n",
    "# Writing to the CSV file\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Writing the header row\n",
    "    writer.writerow(['Chapter', 'Index', 'Text'])\n",
    "    \n",
    "    for index, paragraph in enumerate(paragraphs, start=1):\n",
    "        # Assuming the first paragraph is the chapter title and skipping it\n",
    "        if index > 1: \n",
    "            writer.writerow([chapter_number, f'{index-1:03}', paragraph])\n",
    "\n",
    "print(f'CSV file \"{csv_file_path}\" has been created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\learning2024\\Learning-2024\\LLM\\labs\\book-rag\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 149 examples [00:00, 2624.79 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Chapter', 'Index', 'Text'],\n",
       "        num_rows: 149\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"Chapter1.md.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# configure client\n",
    "api_key = '<PINECONE API KEY HERE>'\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec, PodSpec\n",
    "\n",
    "use_serverless = False\n",
    "\n",
    "if use_serverless:\n",
    "    spec = ServerlessSpec(cloud='aws', region='us-west-2')\n",
    "else:\n",
    "    spec = PodSpec(environment='gcp-starter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index on Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'book-rag'\n",
    "\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        spec=spec,\n",
    "        metric='cosine'\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "apikey = '<OPENAI API KEY HERE>'\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Chapter', 'Index', 'Text'],\n",
       "    num_rows: 149\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for showing progress bars during loops\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Convert the dataset into a pandas DataFrame for easier manipulation\n",
    "data = dataset['train'].to_pandas()\n",
    "\n",
    "# Set the size of batches for processing to reduce memory usage\n",
    "batch_size = 100\n",
    "\n",
    "# Loop through the dataset in batches to process and index the data\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    # Calculate the end index for the current batch, ensuring it does not exceed the dataset's length\n",
    "    i_end = min(len(data), i + batch_size)\n",
    "    \n",
    "    # Select the current batch from the dataset\n",
    "    batch = data.iloc[i:i_end]\n",
    "    \n",
    "    # Generate unique identifiers for each document in the batch\n",
    "    # using a combination of DOI and chunk ID\n",
    "    ids = [f\"{x['Chapter']} - {x['Index']}\" for i, x in batch.iterrows()]\n",
    "    \n",
    "    # Extract the text content of each document in the batch\n",
    "    texts = [x['Text'] for _, x in batch.iterrows()]\n",
    "    \n",
    "    # Use the embedding model to generate embeddings for each document's text content\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    \n",
    "    # Prepare metadata for each document in the batch, including the text content,\n",
    "    # source, and title for additional context and searchability\n",
    "    metadata = [\n",
    "        {'text': x['Text']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Insert or update the documents in the Pinecone vector database with the generated\n",
    "    # identifiers, embeddings, and metadata for each document\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00149,\n",
       " 'namespaces': {'': {'vector_count': 149}},\n",
       " 'total_vector_count': 149}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\learning2024\\Learning-2024\\LLM\\labs\\book-rag\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.vectorstores.pinecone.Pinecone` was deprecated in langchain-community 0.0.18 and will be removed in 0.2.0. An updated version of the class exists in the langchain-pinecone package and should be used instead. To use it run `pip install -U langchain-pinecone` and import as `from langchain_pinecone import Pinecone`.\n",
      "  warn_deprecated(\n",
      "c:\\dev\\learning2024\\Learning-2024\\LLM\\labs\\book-rag\\venv\\lib\\site-packages\\langchain_community\\vectorstores\\pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "vectorstore = Pinecone(index, embed_model.embed_query, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the future of longevity?\"\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
