{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Chatbot with Upstage Solar API Endpoint, Langchain and Gradio\n",
    "\n",
    "This lab goes through the creation of a chatbot with the following details :\n",
    "- Uses the Solar LLM API endpoint from Upstage.\n",
    "- Uses Langchain for simplifying the API calls to Upstage Solar API and to also maintain context (chat history)\n",
    "- Uses Gradio for the simple chatbot UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install the python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade -q langchain langchain-community langchainhub langchain-openai llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade -q gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the Solar API Endpoint key and setup the base url\n",
    "\n",
    "Note that you will need to signup for the Solar API endpoint. It is in a free beta until the end of March 2024. From there, you can get your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "BASE_URL = 'https://api.upstage.ai/v1/solar'\n",
    "APIKEY = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Let's test out the Solar API with a simple chat API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm just a computer program, so I don't have feelings or emotions, but I'm here to help you with any questions or problems you may have. How can I assist you today?\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat_model = ChatOpenAI(base_url=BASE_URL, model_name=\"solar-1-mini-chat\", api_key=APIKEY)\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Hi, how are you?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "response = chat_model.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. And here is the code for the full chatbot\n",
    "\n",
    "- I think this code is pretty self explanatory.\n",
    "- Note that it won't work necessarily in a cloud hosted notebook (like on Azure or maybe Google Colab). I don't think so anyway. The gradio chatbot assumes localhost. Personally, I did this with vscode and it worked quite well. Gardio runs very well on vscode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7876\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1\n",
      "h2\n",
      "h3\n",
      "content='Hello! How can I help you today?'\n",
      "h1\n",
      "h2\n",
      "h3\n",
      "content=\"The sky can be many different colors depending on the time of day and the weather. During the day, it's usually a bright blue color, but at sunrise and sunset, it can turn pink or orange. At night, it's usually dark, but you might be able to see stars if it's clear out.\"\n",
      "h1\n",
      "h2\n",
      "h3\n",
      "content='Yes, I\\'m familiar with the poem \"The Walrus and the Carpenter\" by Lewis Carroll. It\\'s a silly and whimsical poem from the same author who wrote \"Alice in Wonderland.\" In the poem, the walrus and the carpenter invite a group of oysters to a feast, but it turns out that the walrus and the carpenter are planning to eat the oysters themselves! It\\'s a fun poem with a twist ending.'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "import time\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_model = ChatOpenAI(base_url=BASE_URL, model_name=\"solar-1-mini-chat\", api_key=APIKEY)\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model\n",
    "\n",
    "def doResponse(user_prompt):\n",
    "    global chat_model, chat_history\n",
    "\n",
    "    chat_history.add_user_message((\"(act as human friend to user. \"\n",
    "                                   \"Don't act like an ai. \"\n",
    "                                   \"Don't act like an assistant. \" \n",
    "                                   \"Do not break character) user prompt: \") + user_prompt)\n",
    "\n",
    "    response = chain.invoke({\"messages\": chat_history.messages})\n",
    "\n",
    "    chat_history.add_ai_message(response)\n",
    "    return response.content\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=300)\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    def respond(message, ch):\n",
    "        time.sleep(2)\n",
    "        bot_message = doResponse(message)\n",
    "        ch.append((message, bot_message))\n",
    "        return \"\", ch\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
