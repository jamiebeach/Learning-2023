{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "I created this notebook to go through some time gradient descent examples. I used ChatGPT to help generate them. Works well!\n",
    "\n",
    "Certainly! Gradient descent is a fundamental optimization algorithm used in machine learning and deep learning to minimize a function. It's particularly useful for training machine learning models. The basic idea behind gradient descent is to iteratively adjust the parameters of the model to find the minimum of the cost function, which measures how far the model's predictions are from the actual outcomes.\n",
    "\n",
    "### How Gradient Descent Works:\n",
    "\n",
    "1. **Objective Function**: In the context of machine learning, you typically have a cost function (or loss function) that you want to minimize. This function measures the difference between the model's prediction and the actual data. For example, in linear regression, a common cost function is the mean squared error.\n",
    "\n",
    "2. **Gradient Calculation**: The gradient of the cost function is calculated with respect to each parameter of the model. The gradient is a vector that points in the direction of the steepest increase of the function. \n",
    "\n",
    "3. **Update Rule**: The parameters of the model are then updated in the opposite direction of the gradient. By doing this, you move towards the minimum of the function. The size of the step taken in each iteration is determined by the learning rate, a hyperparameter that you choose.\n",
    "\n",
    "4. **Iteration**: This process is repeated iteratively until the cost function converges to a minimum.\n",
    "\n",
    "### The Update Rule in Detail:\n",
    "\n",
    "If $\\theta$ represents the parameters of the model and $J(\\theta)$ is the cost function, the update rule of gradient descent can be written as:\n",
    "\n",
    "$$\\theta := \\theta - \\alpha \\cdot \\nabla J(\\theta)$$\n",
    "\n",
    "Where:\n",
    "- $\\theta$ is a vector of parameters.\n",
    "- $\\alpha$ is the learning rate.\n",
    "- $\\nabla J(\\theta)$ is the gradient of the cost function with respect to $\\theta$.\n",
    "\n",
    "### Types of Gradient Descent:\n",
    "\n",
    "1. **Batch Gradient Descent**: Computes the gradient using the entire dataset. This is computationally expensive and slow with very large datasets but provides a stable gradient descent convergence.\n",
    "\n",
    "2. **Stochastic Gradient Descent (SGD)**: Computes the gradient using a single sample at each iteration. This is much faster and can handle large datasets, but the convergence is noisier (less stable) compared to batch gradient descent.\n",
    "\n",
    "3. **Mini-batch Gradient Descent**: A compromise between batch and stochastic gradient descent. It computes the gradient using a small subset of the data at each iteration. This is often the method of choice as it offers a balance between computational efficiency and convergence stability.\n",
    "\n",
    "### Key Points to Remember:\n",
    "\n",
    "- **Learning Rate**: Choosing the right learning rate is crucial. If it's too small, the algorithm will be slow to converge. If it's too large, it might overshoot the minimum and fail to converge.\n",
    "\n",
    "- **Convergence**: You need to decide when to stop the algorithm. This could be after a fixed number of iterations, or when the change in the cost function between iterations falls below a certain threshold.\n",
    "\n",
    "- **Feature Scaling**: Gradient descent converges faster if all features are on a similar scale (e.g., using standardization or normalization), especially in the presence of high-dimensional data.\n",
    "\n",
    "In summary, gradient descent is a powerful optimization algorithm used to minimize the cost function in various machine learning algorithms. Its effectiveness depends on the proper tuning of hyperparameters and an understanding of the underlying data and model characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implementing Gradient Descent from Scratch\n",
    "\n",
    "**Objective**: Implement the basic gradient descent algorithm to find the minimum of a simple function, like a quadratic function $f(x) = x^2$.\n",
    "\n",
    "**Steps**:\n",
    "1. Define the function and its derivative.\n",
    "2. Choose a starting point (initial guess).\n",
    "3. Implement the gradient descent update rule: $x_{\\text{new}} = x_{\\text{old}} - \\eta \\cdot \\nabla f(x_{\\text{old}})$, where $\\eta$ is the learning rate.\n",
    "4. Iterate this process until convergence (e.g., the change in $x$ is below a small threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: x = 8.0, f(x) = 64.0\n",
      "Iteration 2: x = 6.4, f(x) = 40.96000000000001\n",
      "Iteration 3: x = 5.12, f(x) = 26.2144\n",
      "Iteration 4: x = 4.096, f(x) = 16.777216\n",
      "Iteration 5: x = 3.2768, f(x) = 10.73741824\n",
      "Iteration 6: x = 2.62144, f(x) = 6.871947673600001\n",
      "Iteration 7: x = 2.0971520000000003, f(x) = 4.398046511104002\n",
      "Iteration 8: x = 1.6777216000000004, f(x) = 2.8147497671065613\n",
      "Iteration 9: x = 1.3421772800000003, f(x) = 1.801439850948199\n",
      "Iteration 10: x = 1.0737418240000003, f(x) = 1.1529215046068475\n",
      "Iteration 11: x = 0.8589934592000003, f(x) = 0.7378697629483825\n",
      "Iteration 12: x = 0.6871947673600002, f(x) = 0.47223664828696477\n",
      "Iteration 13: x = 0.5497558138880001, f(x) = 0.3022314549036574\n",
      "Iteration 14: x = 0.43980465111040007, f(x) = 0.19342813113834073\n",
      "Iteration 15: x = 0.35184372088832006, f(x) = 0.12379400392853807\n",
      "Iteration 16: x = 0.281474976710656, f(x) = 0.07922816251426434\n",
      "Iteration 17: x = 0.22517998136852482, f(x) = 0.050706024009129186\n",
      "Iteration 18: x = 0.18014398509481985, f(x) = 0.03245185536584268\n",
      "Iteration 19: x = 0.14411518807585588, f(x) = 0.020769187434139313\n",
      "Iteration 20: x = 0.11529215046068471, f(x) = 0.013292279957849162\n",
      "Iteration 21: x = 0.09223372036854777, f(x) = 0.008507059173023463\n",
      "Iteration 22: x = 0.07378697629483821, f(x) = 0.0054445178707350165\n",
      "Iteration 23: x = 0.05902958103587057, f(x) = 0.00348449143727041\n",
      "Iteration 24: x = 0.04722366482869646, f(x) = 0.002230074519853063\n",
      "Iteration 25: x = 0.037778931862957166, f(x) = 0.0014272476927059603\n",
      "Minimum occurs at x = 0.037778931862957166\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    \"\"\"Function to minimize, f(x) = x^2.\"\"\"\n",
    "    return x ** 2\n",
    "\n",
    "def df(x):\n",
    "    \"\"\"Derivative of f(x), df(x) = 2x.\"\"\"\n",
    "    return 2 * x\n",
    "\n",
    "def gradient_descent(starting_point, learning_rate, num_iterations):\n",
    "    \"\"\"Performs gradient descent to find the minimum of a function.\n",
    "\n",
    "    Args:\n",
    "    starting_point (float): Initial guess for the minimum.\n",
    "    learning_rate (float): Step size for each iteration.\n",
    "    num_iterations (int): Number of iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "    float: The approximate minimum point of the function.\n",
    "    \"\"\"\n",
    "    x = starting_point\n",
    "    for i in range(num_iterations):\n",
    "        grad = df(x)  # Compute the gradient at the current point\n",
    "        x = x - learning_rate * grad  # Update the current point\n",
    "        print(f\"Iteration {i+1}: x = {x}, f(x) = {f(x)}\")\n",
    "\n",
    "    return x\n",
    "\n",
    "# Parameters\n",
    "starting_point = 10  # Initial guess\n",
    "learning_rate = 0.1  # Step size\n",
    "num_iterations = 25  # Number of steps\n",
    "\n",
    "# Perform gradient descent\n",
    "minimum = gradient_descent(starting_point, learning_rate, num_iterations)\n",
    "print(f\"Minimum occurs at x = {minimum}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "\n",
    "1. **Function Definitions**: `f(x)` is the function we want to minimize, and `df(x)` is its derivative.\n",
    "\n",
    "2. **Gradient Descent Function**:\n",
    "   - `starting_point`: Where to start the descent.\n",
    "   - `learning_rate`: How big a step to take in each iteration. A smaller step size might take longer to converge, while a larger step size might overshoot.\n",
    "   - `num_iterations`: How many steps to take.\n",
    "\n",
    "3. **Gradient Descent Process**:\n",
    "   - In each iteration, we compute the gradient at the current point (`df(x)`).\n",
    "   - We then update the current point (`x`) by moving in the direction opposite to the gradient. The amount we move is determined by the `learning_rate`.\n",
    "\n",
    "4. **Running the Algorithm**: We call `gradient_descent` with an initial guess of 10, a learning rate of 0.1, and for 25 iterations.\n",
    "\n",
    "5. **Output**: The function prints the value of `x` and `f(x)` at each iteration and finally returns the point where the function reaches its minimum.\n",
    "\n",
    "This script will show how `x` moves closer to 0 (the minimum of \\( f(x) = x^2 \\)) with each iteration. Adjusting the learning rate and the number of iterations can provide insights into how gradient descent behaves under different settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear Regression with Gradient Descent\n",
    "\n",
    "**Objective**: Implement linear regression using gradient descent to fit a line to a set of points.\n",
    "\n",
    "**Steps**:\n",
    "1. Generate a synthetic dataset: pairs of $(x, y)$ points.\n",
    "2. Define the hypothesis $h(x) = \\theta_0 + \\theta_1 x$.\n",
    "3. Define the cost function (mean squared error).\n",
    "4. Compute the gradients of the cost function with respect to $\\theta_0$ and $\\theta_1$.\n",
    "5. Update $\\theta_0$ and $\\theta_1$ using gradient descent.\n",
    "6. Iterate until convergence and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid function for logistic regression.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def predict(features, weights):\n",
    "    \"\"\"Return probability predictions for a given set of features and weights.\"\"\"\n",
    "    # Linear combination of weights and features\n",
    "    z = np.dot(features, weights)\n",
    "    return sigmoid(z)\n",
    "\n",
    "def cost_function(features, labels, weights):\n",
    "    \"\"\"Compute the cost function for logistic regression.\"\"\"\n",
    "    observations = len(labels)\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    # Cost for class 1 and class 0 predictions\n",
    "    class1_cost = -labels * np.log(predictions)\n",
    "    class2_cost = -(1 - labels) * np.log(1 - predictions)\n",
    "\n",
    "    # Sum and average cost\n",
    "    cost = class1_cost + class2_cost\n",
    "    cost = cost.sum() / observations\n",
    "\n",
    "    return cost\n",
    "\n",
    "def update_weights(features, labels, weights, lr):\n",
    "    \"\"\"Update weights using gradient descent.\"\"\"\n",
    "    N = len(features)\n",
    "\n",
    "    # Calculate predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    # Gradient for logistic regression\n",
    "    gradient = np.dot(features.T, predictions - labels)\n",
    "    gradient /= N\n",
    "    gradient *= lr\n",
    "\n",
    "    # Update weights\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights\n",
    "\n",
    "def train(features, labels, weights, lr, iters):\n",
    "    \"\"\"Train the logistic regression model.\"\"\"\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "\n",
    "        # Logging progress\n",
    "        if i % 100 == 0:\n",
    "            cost = cost_function(features, labels, weights)\n",
    "            print(f\"iteration: {i}, cost: {cost}\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Generate a synthetic dataset for binary classification\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, n_clusters_per_class=1)\n",
    "\n",
    "# Add an intercept term to the features matrix\n",
    "intercept = np.ones((X.shape[0], 1))\n",
    "X = np.concatenate((intercept, X), axis=1)\n",
    "\n",
    "# Initialize weights to zero\n",
    "weights = np.zeros(X.shape[1])\n",
    "\n",
    "# Set hyperparameters for the learning process\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "\n",
    "# Train the logistic regression model\n",
    "weights = train(X, y, weights, learning_rate, num_iterations)\n",
    "\n",
    "# Plotting the data and decision boundary\n",
    "plt.scatter(X[:, 1], X[:, 2], marker='o', c=y)\n",
    "\n",
    "# Calculate values for decision boundary line\n",
    "x_values = [np.min(X[:, 1] - 1), np.max(X[:, 2] + 1)]\n",
    "y_values = - (weights[0] + np.dot(weights[1], x_values)) / weights[2]\n",
    "\n",
    "plt.plot(x_values, y_values, label='Decision Boundary')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
